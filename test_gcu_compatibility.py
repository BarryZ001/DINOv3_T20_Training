#!/usr/bin/env python3
"""
强化版 GCU 兼容性测试脚本
测试所有 CUDA 特定功能的禁用是否生效
"""

import os
import sys

# 🔧 强化版GCU兼容性设置 - 彻底禁用所有CUDA特定功能
print("🔧 设置强化版GCU兼容性环境变量...")

# DeepSpeed CUDA特定组件禁用
os.environ['DEEPSPEED_DISABLE_FUSED_ADAM'] = '1'
os.environ['DS_BUILD_FUSED_ADAM'] = '0'
os.environ['DS_BUILD_CPU_ADAM'] = '1'  # 强制使用CPU版本的Adam
os.environ['DS_BUILD_UTILS'] = '0'  # 禁用其他CUDA特定工具
os.environ['DS_BUILD_AIO'] = '0'  # 禁用异步IO（可能依赖CUDA）
os.environ['DS_BUILD_SPARSE_ATTN'] = '0'  # 禁用稀疏注意力（CUDA特定）

# 额外的CUDA特定功能禁用
os.environ['DS_BUILD_FUSED_LAMB'] = '0'  # 禁用FusedLamb优化器
os.environ['DS_BUILD_TRANSFORMER'] = '0'  # 禁用CUDA Transformer内核
os.environ['DS_BUILD_STOCHASTIC_TRANSFORMER'] = '0'  # 禁用随机Transformer
os.environ['DS_BUILD_TRANSFORMER_INFERENCE'] = '0'  # 禁用Transformer推理内核
os.environ['DS_BUILD_QUANTIZER'] = '0'  # 禁用量化器（可能依赖CUDA）
os.environ['DS_BUILD_RANDOM_LTD'] = '0'  # 禁用随机LTD

# PyTorch CUDA相关设置
os.environ['CUDA_VISIBLE_DEVICES'] = ''  # 隐藏CUDA设备
os.environ['TORCH_CUDA_ARCH_LIST'] = ''  # 清空CUDA架构列表

# 强制使用CPU后端进行某些操作
os.environ['OMP_NUM_THREADS'] = '4'  # 限制OpenMP线程数

print("✅ 环境变量设置完成")

try:
    import torch
    print(f"✅ PyTorch 导入成功: {torch.__version__}")
    
    # 检查CUDA可用性
    if torch.cuda.is_available():
        print("⚠️  CUDA 仍然可用，但已通过环境变量禁用相关功能")
    else:
        print("✅ CUDA 不可用，符合预期")
        
except ImportError as e:
    print(f"❌ PyTorch 导入失败: {e}")
    sys.exit(1)

try:
    import deepspeed
    print(f"✅ DeepSpeed 导入成功: {deepspeed.__version__}")
    
    # 测试 DeepSpeed 配置加载
    try:
        # 加载配置文件
        config_path = "configs/train_dinov3_mmrs1m_t20_gcu_8card.py"
        
        # 动态导入配置
        import importlib.util
        spec = importlib.util.spec_from_file_location("config", config_path)
        config_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(config_module)
        
        deepspeed_config = config_module.deepspeed_config
        print("✅ DeepSpeed 配置加载成功")
        
        # 检查关键配置
        print(f"📋 train_batch_size: {deepspeed_config.get('train_batch_size')}")
        print(f"📋 train_micro_batch_size_per_gpu: {deepspeed_config.get('train_micro_batch_size_per_gpu')}")
        print(f"📋 gradient_accumulation_steps: {deepspeed_config.get('gradient_accumulation_steps')}")
        print(f"📋 disable_fused_adam: {deepspeed_config.get('disable_fused_adam')}")
        
        optimizer_config = deepspeed_config.get('optimizer', {})
        print(f"📋 optimizer type: {optimizer_config.get('type')}")
        
        # 创建一个简单的模型进行测试
        import torch.nn as nn
        
        class SimpleModel(nn.Module):
            def __init__(self):
                super().__init__()
                self.linear = nn.Linear(10, 1)
                
            def forward(self, x):
                return self.linear(x)
        
        model = SimpleModel()
        print("✅ 测试模型创建成功")
        
        # 🔧 关键修正 (1/2): 在调用initialize之前，手动创建一个标准的PyTorch优化器
        # 从DeepSpeed配置中获取优化器参数
        optimizer_params = deepspeed_config.get('optimizer', {}).get('params', {})
        optimizer = torch.optim.AdamW(model.parameters(), **optimizer_params)
        print(f"✅ 手动创建优化器成功: {type(optimizer).__name__}")
        
        # 模拟单卡环境的批次大小验证
        world_size = 1  # 单卡测试
        expected_batch_size = (deepspeed_config.get('train_micro_batch_size_per_gpu', 8) * 
                             deepspeed_config.get('gradient_accumulation_steps', 1) * 
                             world_size)
        
        print(f"📊 期望的 train_batch_size: {expected_batch_size}")
        print(f"📊 配置的 train_batch_size: {deepspeed_config.get('train_batch_size')}")
        
        if deepspeed_config.get('train_batch_size') == expected_batch_size:
            print("✅ 批次大小配置匹配")
        else:
            print("⚠️  批次大小配置不匹配，但这在多卡环境中可能是正常的")
        
        # 🚀 尝试 DeepSpeed 初始化
        print("🚀 尝试初始化 DeepSpeed...")
        
        # 🔧 关键修正 (2/2): 将手动创建的optimizer实例传递给initialize函数
        model_engine, optimizer, _, _ = deepspeed.initialize(
            model=model,
            model_parameters=model.parameters(),
            optimizer=optimizer,  # <--- 将优化器实例传入
            config=deepspeed_config
        )
        
        print("🎉 DeepSpeed 初始化成功！")
        print(f"✅ 使用的优化器: {type(optimizer).__name__}")
        
    except Exception as e:
        print(f"❌ DeepSpeed 初始化失败: {e}")
        print("🔧 可能的原因：")
        print("   1. 批次大小配置问题")
        print("   2. 仍有CUDA特定组件未被禁用")
        print("   3. 其他配置参数错误")
        
except ImportError as e:
    print(f"❌ DeepSpeed 导入失败: {e}")
    print("💡 这是正常的，因为在本地环境中可能缺少某些依赖")

print("\n📋 强化版GCU兼容性测试总结：")
print("1. ✅ 环境变量设置：彻底禁用所有CUDA特定功能")
print("2. ✅ DeepSpeed 配置：使用 AdamW 优化器")
print("3. 🔧 批次大小修复：确保单卡和多卡环境兼容")
print("4. 🚀 准备在 T20 服务器上进行完整测试")
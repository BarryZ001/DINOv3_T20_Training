#!/usr/bin/env python3
"""
DeepSpeed åˆå§‹åŒ–æµ‹è¯•è„šæœ¬
ç”¨äºå®šä½ DeepSpeed åˆ†å¸ƒå¼è®­ç»ƒåˆå§‹åŒ–é˜¶æ®µçš„æ­»å¾ªç¯é—®é¢˜
"""

import os
import sys
import time
import signal
import torch

# å°è¯•å¯¼å…¥å¯èƒ½åœ¨Macç¯å¢ƒä¸‹ä¸å¯ç”¨çš„æ¨¡å—
try:
    import torch_gcu
    torch_gcu_available = True
except ImportError:
    torch_gcu_available = False
    print("âš ï¸ torch_gcu åœ¨å½“å‰ç¯å¢ƒä¸‹ä¸å¯ç”¨")

try:
    from mmengine.config import Config
    mmengine_config_available = True
except ImportError:
    mmengine_config_available = False
    print("âš ï¸ mmengine.config åœ¨å½“å‰ç¯å¢ƒä¸‹ä¸å¯ç”¨")

try:
    from mmengine.dataset import pseudo_collate as collate
    mmengine_dataset_available = True
except ImportError:
    mmengine_dataset_available = False
    print("âš ï¸ mmengine.dataset åœ¨å½“å‰ç¯å¢ƒä¸‹ä¸å¯ç”¨")

def signal_handler(signum, frame):
    print(f"\nğŸš¨ æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨é€€å‡º...")
    sys.exit(1)

# è®¾ç½®ä¿¡å·å¤„ç†å™¨
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

def test_basic_torch_distributed():
    """æµ‹è¯•åŸºç¡€çš„ torch.distributed åˆå§‹åŒ–"""
    print("\n=== æµ‹è¯•1: åŸºç¡€ torch.distributed åˆå§‹åŒ– ===")
    
    try:
        # æ£€æŸ¥torch.distributedæ˜¯å¦å¯ç”¨
        if not hasattr(torch, 'distributed'):
            print("âŒ torch.distributed åœ¨å½“å‰ç¯å¢ƒä¸‹ä¸å¯ç”¨")
            return False
            
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['MASTER_ADDR'] = '127.0.0.1'
        os.environ['MASTER_PORT'] = '29500'
        os.environ['RANK'] = '0'
        os.environ['WORLD_SIZE'] = '1'
        os.environ['LOCAL_RANK'] = '0'
        
        print("ğŸ”§ ç¯å¢ƒå˜é‡è®¾ç½®å®Œæˆ")
        print(f"   MASTER_ADDR: {os.environ.get('MASTER_ADDR')}")
        print(f"   MASTER_PORT: {os.environ.get('MASTER_PORT')}")
        print(f"   RANK: {os.environ.get('RANK')}")
        print(f"   WORLD_SIZE: {os.environ.get('WORLD_SIZE')}")
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»åˆå§‹åŒ–
        if torch.distributed.is_initialized():
            print("âš ï¸ torch.distributed å·²ç»åˆå§‹åŒ–")
            torch.distributed.destroy_process_group()
            print("ğŸ”„ å·²é”€æ¯ç°æœ‰è¿›ç¨‹ç»„")
        
        print("ğŸš€ å¼€å§‹åˆå§‹åŒ– torch.distributed...")
        
        # æ£€æµ‹å¯ç”¨çš„åç«¯
        available_backends = []
        if torch.distributed.is_nccl_available():
            available_backends.append('nccl')
        if torch.distributed.is_gloo_available():
            available_backends.append('gloo')
        if torch.distributed.is_mpi_available():
            available_backends.append('mpi')
            
        print(f"ğŸ” å¯ç”¨çš„åˆ†å¸ƒå¼åç«¯: {available_backends}")
        
        # é€‰æ‹©åˆé€‚çš„åç«¯
        backend = 'gloo'  # é»˜è®¤ä½¿ç”¨glooï¼Œå…¼å®¹æ€§æ›´å¥½
        if torch_gcu_available and 'nccl' in available_backends:
            # å¦‚æœæœ‰GCUä¸”NCCLå¯ç”¨ï¼Œå°è¯•ä½¿ç”¨nccl
            backend = 'nccl'
            print(f"ğŸ”¥ æ£€æµ‹åˆ°GCUç¯å¢ƒï¼Œå°è¯•ä½¿ç”¨ {backend} åç«¯")
        else:
            print(f"ğŸ”§ ä½¿ç”¨ {backend} åç«¯è¿›è¡Œåˆå§‹åŒ–")
        
        # åˆå§‹åŒ–åˆ†å¸ƒå¼è¿›ç¨‹ç»„
        torch.distributed.init_process_group(
            backend=backend,
            init_method='env://',
            world_size=1,
            rank=0,
            timeout=torch.distributed.default_pg_timeout
        )
        
        print("âœ… torch.distributed åˆå§‹åŒ–æˆåŠŸ")
        print(f"   Backend: {torch.distributed.get_backend()}")
        print(f"   World Size: {torch.distributed.get_world_size()}")
        print(f"   Rank: {torch.distributed.get_rank()}")
        
        return True
        
    except Exception as e:
        print(f"âŒ torch.distributed åˆå§‹åŒ–å¤±è´¥: {e}")
        return False

def test_deepspeed_import_and_config():
    """æµ‹è¯• DeepSpeed å¯¼å…¥å’Œé…ç½®"""
    print("\n=== æµ‹è¯•2: DeepSpeed å¯¼å…¥å’Œé…ç½® ===")
    
    try:
        import deepspeed
        print(f"âœ… DeepSpeed å¯¼å…¥æˆåŠŸï¼Œç‰ˆæœ¬: {deepspeed.__version__}")
        
        # æµ‹è¯• DeepSpeed é…ç½®
        ds_config = {
            "train_batch_size": 16,
            "train_micro_batch_size_per_gpu": 2,
            "gradient_accumulation_steps": 1,
            "optimizer": {
                "type": "AdamW",
                "params": {
                    "lr": 1e-4,
                    "betas": [0.9, 0.999],
                    "eps": 1e-8,
                    "weight_decay": 0.01
                }
            },
            "scheduler": {
                "type": "WarmupLR",
                "params": {
                    "warmup_min_lr": 0,
                    "warmup_max_lr": 1e-4,
                    "warmup_num_steps": 1000
                }
            },
            "fp16": {
                "enabled": True,
                "loss_scale": 0,
                "loss_scale_window": 1000,
                "hysteresis": 2,
                "min_loss_scale": 1
            },
            "zero_optimization": {
                "stage": 2,
                "allgather_partitions": True,
                "allgather_bucket_size": 2e8,
                "overlap_comm": True,
                "reduce_scatter": True,
                "reduce_bucket_size": 2e8,
                "contiguous_gradients": True
            }
        }
        
        print("âœ… DeepSpeed é…ç½®åˆ›å»ºæˆåŠŸ")
        return ds_config
        
    except Exception as e:
        print(f"âŒ DeepSpeed å¯¼å…¥æˆ–é…ç½®å¤±è´¥: {e}")
        return None

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("\n=== æµ‹è¯•3: æ¨¡å‹åˆ›å»º ===")
    
    try:
        # åŠ è½½é…ç½®
        config_path = '/workspace/code/DINOv3_T20_Training/configs/train_dinov3_mmrs1m_t20_gcu_8card.py'
        cfg = Config.fromfile(config_path)
        
        # åˆ›å»ºæ¨¡å‹
        from mmengine.registry import MODELS
        model = MODELS.build(cfg.model)
        print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # è®¾ç½®è®¾å¤‡
        device = torch.device('gcu:0' if torch.cuda.is_available() else 'cpu')
        model = model.to(device)
        print(f"âœ… æ¨¡å‹ç§»åŠ¨åˆ°è®¾å¤‡: {device}")
        
        return model, device
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return None, None

def test_deepspeed_initialization():
    """æµ‹è¯• DeepSpeed åˆå§‹åŒ–"""
    print("\n=== æµ‹è¯•4: DeepSpeed åˆå§‹åŒ– ===")
    
    try:
        import deepspeed
        
        # è·å–æ¨¡å‹å’Œé…ç½®
        model, device = test_model_creation()
        if model is None:
            return False
            
        ds_config = test_deepspeed_import_and_config()
        if ds_config is None:
            return False
        
        print("ğŸš€ å¼€å§‹ DeepSpeed åˆå§‹åŒ–...")
        print("âš ï¸ è¿™é‡Œå¯èƒ½ä¼šå‡ºç°æ­»å¾ªç¯ï¼Œç­‰å¾…30ç§’...")
        
        # è®¾ç½®è¶…æ—¶
        start_time = time.time()
        timeout = 30  # 30ç§’è¶…æ—¶
        
        # åœ¨å­è¿›ç¨‹ä¸­å°è¯•åˆå§‹åŒ–
        try:
            model_engine, optimizer, _, _ = deepspeed.initialize(
                model=model,
                config=ds_config,
                model_parameters=model.parameters()
            )
            
            elapsed = time.time() - start_time
            print(f"âœ… DeepSpeed åˆå§‹åŒ–æˆåŠŸï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
            return True
            
        except Exception as init_error:
            elapsed = time.time() - start_time
            print(f"âŒ DeepSpeed åˆå§‹åŒ–å¤±è´¥ï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
            print(f"   é”™è¯¯: {init_error}")
            return False
            
    except Exception as e:
        print(f"âŒ DeepSpeed åˆå§‹åŒ–æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_launcher_mode():
    """æµ‹è¯•ä¸åŒçš„å¯åŠ¨æ¨¡å¼"""
    print("\n=== æµ‹è¯•5: å¯åŠ¨æ¨¡å¼æ£€æŸ¥ ===")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    env_vars = [
        'RANK', 'WORLD_SIZE', 'LOCAL_RANK', 'MASTER_ADDR', 'MASTER_PORT',
        'CUDA_VISIBLE_DEVICES', 'OMPI_COMM_WORLD_RANK', 'PMI_RANK'
    ]
    
    print("ğŸ” ç¯å¢ƒå˜é‡æ£€æŸ¥:")
    for var in env_vars:
        value = os.environ.get(var, 'Not Set')
        print(f"   {var}: {value}")
    
    # æ£€æŸ¥å¯åŠ¨æ–¹å¼
    if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:
        print("ğŸš€ æ£€æµ‹åˆ°åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ")
        rank = int(os.environ.get('RANK', 0))
        world_size = int(os.environ.get('WORLD_SIZE', 1))
        local_rank = int(os.environ.get('LOCAL_RANK', 0))
        
        print(f"   Rank: {rank}")
        print(f"   World Size: {world_size}")
        print(f"   Local Rank: {local_rank}")
        
        if world_size > 1:
            print("âš ï¸ å¤šè¿›ç¨‹åˆ†å¸ƒå¼è®­ç»ƒå¯èƒ½å¯¼è‡´æ­»å¾ªç¯")
            return False
    else:
        print("ğŸ”§ å•è¿›ç¨‹æ¨¡å¼")
        return True

def main():
    print("ğŸ” DeepSpeed åˆå§‹åŒ–æ­»å¾ªç¯è°ƒè¯•æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•å¯åŠ¨æ¨¡å¼
    if not test_launcher_mode():
        print("\nâŒ æ£€æµ‹åˆ°å¯èƒ½å¯¼è‡´æ­»å¾ªç¯çš„åˆ†å¸ƒå¼ç¯å¢ƒ")
        return
    
    # æµ‹è¯•åŸºç¡€åˆ†å¸ƒå¼åˆå§‹åŒ–
    if not test_basic_torch_distributed():
        print("\nâŒ åŸºç¡€åˆ†å¸ƒå¼åˆå§‹åŒ–å¤±è´¥ï¼Œè·³è¿‡åç»­æµ‹è¯•")
        return
    
    # æµ‹è¯• DeepSpeed åˆå§‹åŒ–
    success = test_deepspeed_initialization()
    
    if success:
        print("\nğŸ‰ DeepSpeed åˆå§‹åŒ–æµ‹è¯•é€šè¿‡ï¼")
        print("ğŸ’¡ é—®é¢˜å¯èƒ½åœ¨äºå¤šè¿›ç¨‹å¯åŠ¨å™¨æˆ–å…¶ä»–ç¯å¢ƒå› ç´ ")
    else:
        print("\nâŒ DeepSpeed åˆå§‹åŒ–å‡ºç°é—®é¢˜")
        print("ğŸ’¡ å»ºè®®æ£€æŸ¥:")
        print("   1. GCU é©±åŠ¨å…¼å®¹æ€§")
        print("   2. DeepSpeed ç‰ˆæœ¬å…¼å®¹æ€§")
        print("   3. åˆ†å¸ƒå¼é€šä¿¡é…ç½®")
        print("   4. å¯åŠ¨å™¨å‚æ•°è®¾ç½®")

if __name__ == "__main__":
    main()
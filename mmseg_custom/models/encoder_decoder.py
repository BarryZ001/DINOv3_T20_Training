#!/usr/bin/env python3
"""
è‡ªå®šä¹‰çš„EncoderDecoderæ¨¡å‹ï¼Œç”¨äºè§£å†³T20æœåŠ¡å™¨ä¸Šçš„æ³¨å†Œè¡¨é—®é¢˜
"""

import torch
import torch.nn as nn
from typing import Dict, List, Optional, Union, Any
from mmengine.model import BaseModel
from mmengine.registry import MODELS


@MODELS.register_module(name='EncoderDecoder')
@MODELS.register_module(name='CustomEncoderDecoder')
class EncoderDecoder(BaseModel):
    """è‡ªå®šä¹‰çš„EncoderDecoderæ¨¡å‹ï¼Œå…¼å®¹T20æœåŠ¡å™¨ç¯å¢ƒ"""
    
    def __init__(self, 
                 backbone: Optional[Dict] = None,
                 decode_head: Optional[Dict] = None,
                 neck: Optional[Dict] = None,
                 auxiliary_head: Optional[Dict] = None,
                 train_cfg: Optional[Dict] = None,
                 test_cfg: Optional[Dict] = None,
                 pretrained: Optional[str] = None,
                 init_cfg: Optional[Dict] = None,
                 data_preprocessor: Optional[Dict] = None,
                 **kwargs):
        super().__init__(init_cfg=init_cfg, data_preprocessor=data_preprocessor)
        
        # å­˜å‚¨é…ç½®ä»¥ä¾›åç»­ä½¿ç”¨
        self.backbone_cfg = backbone
        self.decode_head_cfg = decode_head
        self.neck_cfg = neck
        self.auxiliary_head_cfg = auxiliary_head
        self.train_cfg = train_cfg
        self.test_cfg = test_cfg
        
        # æ„å»ºæ¨¡å‹ç»„ä»¶
        if backbone is not None:
            self.backbone = MODELS.build(backbone)
        else:
            self.backbone = nn.Identity()
            
        if neck is not None:
            self.neck = MODELS.build(neck)
        else:
            self.neck = None
            
        if decode_head is not None:
            self.decode_head = MODELS.build(decode_head)
        else:
            self.decode_head = nn.Identity()
            
        if auxiliary_head is not None:
            self.auxiliary_head = MODELS.build(auxiliary_head)
        else:
            self.auxiliary_head = None
    
    def extract_feat(self, inputs: torch.Tensor) -> List[torch.Tensor]:
        """æå–ç‰¹å¾"""
        x = self.backbone(inputs)
        if self.neck is not None:
            x = self.neck(x)
        # ç¡®ä¿è¿”å›List[torch.Tensor]ç±»å‹
        if isinstance(x, torch.Tensor):
            return [x]
        elif isinstance(x, (list, tuple)):
            return [feat if isinstance(feat, torch.Tensor) else torch.tensor(feat) for feat in x]
        else:
            return [torch.tensor(x)]
    
    def encode_decode(self, inputs: torch.Tensor, batch_img_metas: List[Dict]) -> torch.Tensor:
        """ç¼–ç -è§£ç è¿‡ç¨‹"""
        x = self.extract_feat(inputs)
        # ç¡®ä¿decode_headå¯è°ƒç”¨
        if hasattr(self.decode_head, '__call__'):
            seg_logits = self.decode_head(x)
        else:
            # å¦‚æœdecode_headæ˜¯Identityæˆ–å…¶ä»–ä¸å¯è°ƒç”¨å¯¹è±¡ï¼Œè¿”å›è¾“å…¥
            seg_logits = x[0] if x else inputs
        return seg_logits
    
    def forward(self, 
                inputs: Union[torch.Tensor, Dict[str, torch.Tensor]], 
                data_samples: Optional[Any] = None, 
                mode: str = 'tensor') -> Union[Dict[str, torch.Tensor], List[Any]]:
        """å‰å‘ä¼ æ’­"""
        
        # ğŸ”§ ä¿®å¤æ•°æ®è¾“å…¥æ ¼å¼å¤„ç† - å…¼å®¹å¤šç§æ•°æ®æ ¼å¼
        if isinstance(inputs, dict):
            # æƒ…å†µ1: æ ‡å‡†MMEngineæ ¼å¼ {'inputs': tensor, 'data_samples': [...]}
            if 'inputs' in inputs:
                actual_inputs = inputs['inputs']
                if data_samples is None and 'data_samples' in inputs:
                    data_samples = inputs['data_samples']
                inputs = actual_inputs
            # æƒ…å†µ2: ç›´æ¥çš„batchæ•°æ®æ ¼å¼ {'img': tensor, 'gt_semantic_seg': tensor, ...}
            elif 'img' in inputs:
                actual_inputs = inputs['img']
                # æ„é€ data_samplesç”¨äºlossè®¡ç®—
                if data_samples is None and 'gt_semantic_seg' in inputs:
                    gt_seg = inputs['gt_semantic_seg']
                    # æ„é€ ç®€å•çš„data_samplesæ ¼å¼
                    batch_size = gt_seg.shape[0] if hasattr(gt_seg, 'shape') else 1
                    data_samples = []
                    for i in range(batch_size):
                        # åˆ›å»ºç®€å•çš„å¯¹è±¡æ¥å­˜å‚¨åˆ†å‰²æ ‡æ³¨
                        sample = {}
                        sample['gt_sem_seg'] = {}
                        sample['gt_sem_seg']['data'] = gt_seg[i] if batch_size > 1 else gt_seg
                        sample['metainfo'] = inputs.get('img_metas', {})
                        data_samples.append(sample)
                inputs = actual_inputs
            else:
                # å¦‚æœæ˜¯å…¶ä»–æ ¼å¼çš„dictï¼Œå°è¯•æ‰¾åˆ°å›¾åƒæ•°æ®
                possible_keys = ['image', 'images', 'input', 'x']
                for key in possible_keys:
                    if key in inputs:
                        inputs = inputs[key]
                        break
                else:
                    raise KeyError(f"Cannot find image data in input dict. Available keys: {list(inputs.keys())}")
        
        # å¦‚æœinputsä»ç„¶ä¸æ˜¯tensorï¼Œå°è¯•è½¬æ¢
        if not isinstance(inputs, torch.Tensor):
            if hasattr(inputs, 'data'):
                inputs = inputs.data
            elif isinstance(inputs, (list, tuple)) and len(inputs) > 0:
                inputs = inputs[0]
        
        if mode == 'loss':
            return self.loss(inputs, data_samples)
        elif mode == 'predict':
            result = self.predict(inputs, data_samples)
            # ç¡®ä¿è¿”å›ç±»å‹ç¬¦åˆBaseModelè¦æ±‚
            return result if isinstance(result, list) else [result]
        elif mode == 'tensor':
            return self._forward(inputs, data_samples)
        else:
            raise RuntimeError(f'Invalid mode "{mode}". '
                             'Only supports loss, predict and tensor mode')
    
    def loss(self, inputs: torch.Tensor, data_samples: Any) -> Dict[str, torch.Tensor]:
        """è®¡ç®—æŸå¤±"""
        x = self.extract_feat(inputs)
        
        losses: Dict[str, torch.Tensor] = {}
        
        # ä¸»è§£ç å¤´æŸå¤±
        if hasattr(self.decode_head, 'loss_by_feat') and callable(self.decode_head.loss_by_feat):
            loss_decode = self.decode_head.loss_by_feat(x, data_samples)
        elif hasattr(self.decode_head, 'loss') and callable(self.decode_head.loss):
            # ä¼ é€’train_cfgå‚æ•°
            loss_decode = self.decode_head.loss(x, data_samples, self.train_cfg)
        else:
            # ç®€å•çš„å ä½ç¬¦æŸå¤±
            loss_decode = {'loss_seg': torch.tensor(0.0, requires_grad=True, device=inputs.device)}
        
        if isinstance(loss_decode, dict):
            losses.update(loss_decode)
        
        # è¾…åŠ©è§£ç å¤´æŸå¤±
        if self.auxiliary_head is not None:
            if hasattr(self.auxiliary_head, 'loss_by_feat') and callable(self.auxiliary_head.loss_by_feat):
                loss_aux = self.auxiliary_head.loss_by_feat(x, data_samples)
            elif hasattr(self.auxiliary_head, 'loss') and callable(self.auxiliary_head.loss):
                # ä¼ é€’train_cfgå‚æ•°
                loss_aux = self.auxiliary_head.loss(x, data_samples, self.train_cfg)
            else:
                loss_aux = {'loss_aux': torch.tensor(0.0, requires_grad=True, device=inputs.device)}
            
            if isinstance(loss_aux, dict):
                losses.update(loss_aux)
        
        return losses
    
    def predict(self, inputs: Union[torch.Tensor, Dict[str, torch.Tensor]], data_samples: Any) -> Any:
        """é¢„æµ‹"""
        # å¤„ç†data_preprocessorçš„è¾“å‡ºæ ¼å¼
        if isinstance(inputs, dict):
            inputs = inputs['inputs']
            
        batch_img_metas = []
        if data_samples is not None:
            if hasattr(data_samples, '__iter__'):
                for sample in data_samples:
                    if hasattr(sample, 'metainfo'):
                        batch_img_metas.append(sample.metainfo)
                    else:
                        batch_img_metas.append({})
            else:
                batch_img_metas = [{}]
        
        seg_logits = self.encode_decode(inputs, batch_img_metas)
        
        # ç®€å•çš„é¢„æµ‹ç»“æœå¤„ç†
        if data_samples is not None:
            # å°†é¢„æµ‹ç»“æœæ·»åŠ åˆ°data_samplesä¸­
            if hasattr(data_samples, '__iter__'):
                for i, sample in enumerate(data_samples):
                    if hasattr(sample, 'pred_sem_seg'):
                        # å‡è®¾seg_logitsçš„å½¢çŠ¶ä¸º[B, C, H, W]
                        if i < seg_logits.shape[0]:
                            pred_mask = seg_logits[i].argmax(dim=0)
                            sample.pred_sem_seg.data = pred_mask
            return data_samples
        else:
            return seg_logits
    
    def _forward(self, inputs: Union[torch.Tensor, Dict[str, torch.Tensor]], data_samples: Optional[Any] = None) -> torch.Tensor:
        """å†…éƒ¨å‰å‘ä¼ æ’­ï¼ˆç”¨äºæ¨ç†ï¼‰"""
        # å¤„ç†data_preprocessorçš„è¾“å‡ºæ ¼å¼
        if isinstance(inputs, dict):
            inputs = inputs['inputs']
            
        return self.encode_decode(inputs, [])
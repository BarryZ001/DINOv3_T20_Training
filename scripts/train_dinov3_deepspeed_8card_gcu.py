#!/usr/bin/env python3
"""
ç‡§åŸT20 DeepSpeedè®­ç»ƒè„šæœ¬ (ç”Ÿäº§ç‰ˆ)
ä½¿ç”¨MMEngineæ„å»ºç»„ä»¶ï¼ŒDeepSpeedé©±åŠ¨è®­ç»ƒ
"""

import argparse
import json
import os
import sys
from pathlib import Path
from typing import Optional, Any

# é¡¹ç›®è·¯å¾„é…ç½®
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ğŸ”§ å¼ºåˆ¶ç¦ç”¨æ··åˆç²¾åº¦è®­ç»ƒ - è§£å†³ free(): invalid pointer é”™è¯¯
# å¿…é¡»åœ¨å¯¼å…¥torchä¹‹å‰è®¾ç½®è¿™äº›ç¯å¢ƒå˜é‡
os.environ.setdefault('GCU_DISABLE_AMP', '1')        # ç¦ç”¨GCUè‡ªåŠ¨æ··åˆç²¾åº¦
os.environ.setdefault('GCU_FORCE_FP32', '1')         # å¼ºåˆ¶GCUä½¿ç”¨float32
os.environ.setdefault('TORCH_GCU_DISABLE_AMP', '1')  # ç¦ç”¨PyTorch GCUæ··åˆç²¾åº¦
os.environ.setdefault('TORCH_DISABLE_AMP', '1')      # ç¦ç”¨PyTorchè‡ªåŠ¨æ··åˆç²¾åº¦
os.environ.setdefault('DEEPSPEED_DISABLE_FP16', '1') # ç¦ç”¨DeepSpeedæ··åˆç²¾åº¦

# ğŸ”§ GCU å†…å­˜åˆ†é…ä¼˜åŒ– - è§£å†³ invalid pointer é”™è¯¯
# ä½¿ç”¨æ›´ä¿å®ˆçš„å†…å­˜åˆ†é…ç­–ç•¥ï¼Œé¿å…å†…å­˜ç¢ç‰‡å’ŒæŒ‡é’ˆé”™è¯¯
os.environ.setdefault('PYTORCH_GCU_ALLOC_CONF', 'max_split_size_mb:128,garbage_collection_threshold:0.6,expandable_segments:False')
# æ·»åŠ é¢å¤–çš„ GCU ç¯å¢ƒå˜é‡ä»¥æé«˜ç¨³å®šæ€§
os.environ.setdefault('GCU_MEMORY_FRACTION', '0.7')  # è¿›ä¸€æ­¥é™åˆ¶å†…å­˜ä½¿ç”¨ï¼Œé¿å…å†…å­˜ç¢ç‰‡
os.environ.setdefault('GCU_ENABLE_LAZY_INIT', '0')   # ç¦ç”¨å»¶è¿Ÿåˆå§‹åŒ–ï¼Œç¡®ä¿ç¡®å®šæ€§è¡Œä¸º
os.environ.setdefault('GCU_SYNC_ALLOC', '1')         # å¯ç”¨åŒæ­¥å†…å­˜åˆ†é…ï¼Œé¿å…å¼‚æ­¥åˆ†é…å¯¼è‡´çš„æŒ‡é’ˆé”™è¯¯
os.environ.setdefault('GCU_DISABLE_CACHING', '1')    # ç¦ç”¨å†…å­˜ç¼“å­˜ï¼Œå¼ºåˆ¶æ¯æ¬¡éƒ½é‡æ–°åˆ†é…

import torch
import numpy as np
from torch.utils.data.dataloader import default_collate

# ğŸ”§ å¼ºåˆ¶è®¾ç½®é»˜è®¤æ•°æ®ç±»å‹ä¸ºfloat32ï¼Œç¡®ä¿æ‰€æœ‰å¼ é‡éƒ½ä½¿ç”¨float32ç²¾åº¦
torch.set_default_dtype(torch.float32)

# æ¡ä»¶å¯¼å…¥æ¨¡å—ï¼Œé¿å…åœ¨å¼€å‘ç¯å¢ƒä¸­çš„å¯¼å…¥é”™è¯¯
torch_gcu_available = False
deepspeed_available = False
mmengine_available = False

# ç±»å‹æ³¨è§£å˜é‡
Config: Optional[Any] = None
MODELS: Optional[Any] = None
DATASETS: Optional[Any] = None
collate: Optional[Any] = None
torch_gcu: Optional[Any] = None
deepspeed: Optional[Any] = None

try:
    import torch_gcu  # type: ignore
    torch_gcu_available = True
except ImportError:
    torch_gcu = None

try:
    import deepspeed  # type: ignore
    deepspeed_available = True
except ImportError:
    deepspeed = None

try:
    from mmengine.config import Config  # type: ignore
    from mmengine.registry import MODELS, DATASETS  # type: ignore
    from mmengine.dataset import pseudo_collate as collate  # type: ignore
    mmengine_available = True
except ImportError:
    Config = None
    MODELS = None
    DATASETS = None
    collate = None

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—ï¼ˆä»…åœ¨MMEngineå¯ç”¨æ—¶ï¼‰
if mmengine_available:
    try:
        import mmseg_custom.models  # type: ignore
        import mmseg_custom.datasets  # type: ignore
        import mmseg_custom.transforms  # type: ignore
    except ImportError:
        pass


# ğŸ”§ æ³¨é‡Šæ‰è‡ªå®šä¹‰ collate å‡½æ•°ï¼Œç°åœ¨ä½¿ç”¨ MMEngine çš„ pseudo_collate
# è¿™ä¸ªå‡½æ•°ä¹‹å‰ç”¨äºå¤„ç† numpy åˆ° tensor çš„è½¬æ¢å’Œ paddingï¼Œ
# ä½†ç°åœ¨æ•°æ®ç®¡é“å·²ç»ä½¿ç”¨ PackSegInputs äº§ç”Ÿæ ‡å‡†çš„ SegDataSample å¯¹è±¡ï¼Œ
# åº”è¯¥ä½¿ç”¨ MMEngine çš„ pseudo_collate æ¥é¿å… RecursionError

# def mmseg_collate_fn(batch, pad_value=0):
#     """
#     mmsegmentation-style collate_fn:
#     - è‡ªåŠ¨æŠŠ numpy è½¬ torch.Tensor
#     - è‡ªåŠ¨ pad ä¿è¯ batch å†…å›¾åƒå°ºå¯¸ä¸€è‡´
#     - ä¿æŒ dict ç»“æ„ (inputs / gt_semantic_seg)
#     """
#     # ... (åŸæœ‰å®ç°å·²æ³¨é‡Š)
#     pass


def build_components(cfg: Any, device_name: str) -> tuple:
    """æ„å»ºè®­ç»ƒç»„ä»¶"""
    if not mmengine_available or DATASETS is None or MODELS is None:
        raise RuntimeError("MMEngine not available")
    
    # æ„å»ºæ•°æ®é›†
    dataset = DATASETS.build(cfg.train_dataloader.dataset)
    
    # æ„å»ºæ¨¡å‹
    model = MODELS.build(cfg.model)
    
    # è®¾ç½®è®¾å¤‡ - ç›´æ¥ä½¿ç”¨device_nameå­—ç¬¦ä¸²ï¼Œå…¼å®¹MMEngineçš„.to()æ–¹æ³•
    model = model.to(device_name)
    
    return model, dataset


def main() -> None:
    """ä¸»è®­ç»ƒå‡½æ•°"""
    # ğŸ”§ å¼ºåŒ–ç‰ˆGCUå…¼å®¹æ€§è®¾ç½® - å½»åº•ç¦ç”¨æ‰€æœ‰CUDAç‰¹å®šåŠŸèƒ½
    # è¿™æ˜¯è§£å†³IndexError: list index out of rangeçš„å…³é”®ç¯å¢ƒå˜é‡è®¾ç½®
    
    # DeepSpeed CUDAç‰¹å®šç»„ä»¶ç¦ç”¨
    os.environ['DEEPSPEED_DISABLE_FUSED_ADAM'] = '1'
    os.environ['DS_BUILD_FUSED_ADAM'] = '0'
    os.environ['DS_BUILD_CPU_ADAM'] = '1'  # å¼ºåˆ¶ä½¿ç”¨CPUç‰ˆæœ¬çš„Adam
    os.environ['DS_BUILD_UTILS'] = '0'  # ç¦ç”¨å…¶ä»–CUDAç‰¹å®šå·¥å…·
    os.environ['DS_BUILD_AIO'] = '0'  # ç¦ç”¨å¼‚æ­¥IOï¼ˆå¯èƒ½ä¾èµ–CUDAï¼‰
    os.environ['DS_BUILD_SPARSE_ATTN'] = '0'  # ç¦ç”¨ç¨€ç–æ³¨æ„åŠ›ï¼ˆCUDAç‰¹å®šï¼‰
    
    # é¢å¤–çš„CUDAç‰¹å®šåŠŸèƒ½ç¦ç”¨
    os.environ['DS_BUILD_FUSED_LAMB'] = '0'  # ç¦ç”¨FusedLambä¼˜åŒ–å™¨
    os.environ['DS_BUILD_TRANSFORMER'] = '0'  # ç¦ç”¨CUDA Transformerå†…æ ¸
    os.environ['DS_BUILD_STOCHASTIC_TRANSFORMER'] = '0'  # ç¦ç”¨éšæœºTransformer
    os.environ['DS_BUILD_TRANSFORMER_INFERENCE'] = '0'  # ç¦ç”¨Transformeræ¨ç†å†…æ ¸
    os.environ['DS_BUILD_QUANTIZER'] = '0'  # ç¦ç”¨é‡åŒ–å™¨ï¼ˆå¯èƒ½ä¾èµ–CUDAï¼‰
    os.environ['DS_BUILD_RANDOM_LTD'] = '0'  # ç¦ç”¨éšæœºLTD
    
    # PyTorch CUDAç›¸å…³è®¾ç½®
    os.environ['CUDA_VISIBLE_DEVICES'] = ''  # éšè—CUDAè®¾å¤‡
    os.environ['TORCH_CUDA_ARCH_LIST'] = ''  # æ¸…ç©ºCUDAæ¶æ„åˆ—è¡¨
    
    # ğŸ”§ GCU åˆ†å¸ƒå¼è®­ç»ƒç‰¹å®šè®¾ç½® - åŸºäºå®˜æ–¹æœ€ä½³å®è·µ
    os.environ['ENFLAME_CLUSTER_PARALLEL'] = 'true'
    os.environ['ENFLAME_ENABLE_EFP'] = 'true'
    os.environ['TOPS_VISIBLE_DEVICES'] = '0,1,2,3,4,5,6,7'
    os.environ['OMP_NUM_THREADS'] = '5'
    os.environ['ECCL_ASYNC_DISABLE'] = 'false'
    os.environ['ENABLE_RDMA'] = 'true'
    os.environ['ECCL_MAX_NCHANNELS'] = '2'
    os.environ['ENFLAME_UMD_FLAGS'] = 'mem_alloc_retry_times=1'
    os.environ['ECCL_RUNTIME_3_0_ENABLE'] = 'true'
    os.environ['ENFLAME_PT_EVALUATE_TENSOR_NEEDED'] = 'false'
    # ğŸ”§ å…³é”®ä¿®å¤ï¼šä½¿ç”¨å¼‚æ­¥å†…å­˜åˆ†é…å™¨ï¼Œé¿å… invalid pointer é”™è¯¯
    os.environ['PYTORCH_GCU_ALLOC_CONF'] = 'backend:topsMallocAsync'  # æ”¹ä¸ºå¼‚æ­¥åˆ†é…å™¨
    
    # ğŸš€ æµæ°´çº¿å¹¶è¡Œé…ç½® - ç‡§åŸå®˜æ–¹æ¨è
    os.environ['TP_SIZE'] = '1'  # å¼ é‡å¹¶è¡Œå¤§å°è®¾ä¸º1
    os.environ['PP_SIZE'] = '8'  # æµæ°´çº¿å¹¶è¡Œå¤§å°è®¾ä¸º8ï¼ˆ8å¡ï¼‰
    os.environ['DP_SIZE'] = '1'  # æ•°æ®å¹¶è¡Œå¤§å°è®¾ä¸º1
    
    # å¼ºåˆ¶ä½¿ç”¨CPUåç«¯è¿›è¡ŒæŸäº›æ“ä½œ
    os.environ['OMP_NUM_THREADS'] = '4'  # é™åˆ¶OpenMPçº¿ç¨‹æ•°
    
    parser = argparse.ArgumentParser(description='DeepSpeed Training')
    parser.add_argument('--config', required=True, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--work-dir', required=True, help='å·¥ä½œç›®å½•')
    parser.add_argument('--deepspeed', required=True, help='DeepSpeedé…ç½®æ–‡ä»¶')
    parser.add_argument('--launcher', default='deepspeed', help='å¯åŠ¨å™¨ç±»å‹')
    parser.add_argument('--local_rank', type=int, default=0, help='æœ¬åœ°rank')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥å¿…è¦æ¨¡å—
    if not mmengine_available or Config is None:
        print("Error: MMEngine not available")
        return
    
    if not deepspeed_available or deepspeed is None:
        print("Error: DeepSpeed not available")
        return
    
    print(f"ğŸ”§ å·²è®¾ç½®ç¯å¢ƒå˜é‡ç¦ç”¨FusedAdamå’Œå…¶ä»–CUDAç‰¹å®šç»„ä»¶ï¼Œç¡®ä¿GCUå…¼å®¹æ€§")
    
    # åŠ è½½é…ç½®
    cfg = Config.fromfile(args.config)
    
    # ç¯å¢ƒè®¾ç½® - ä½¿ç”¨xlaè®¾å¤‡æ ¼å¼ä»¥å…¼å®¹MMEngine
    if torch_gcu_available and torch_gcu is not None:
        device_id = torch_gcu.current_device()
        device_name = f'xla:{device_id}'
    else:
        device_name = 'cuda'
    
    # æ„å»ºç»„ä»¶
    model, dataset = build_components(cfg, device_name)
    
    # åŠ è½½DeepSpeedé…ç½®
    with open(args.deepspeed, 'r') as f:
        deepspeed_config = json.load(f)
    
    # ğŸ”§ åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒ - åŸºäºç‡§åŸå®˜æ–¹æœ€ä½³å®è·µ
    print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–ç‡§åŸGCUåˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ...")
    
    # ğŸ”§ è·å–åˆ†å¸ƒå¼è®­ç»ƒå‚æ•°
    local_rank = args.local_rank if hasattr(args, 'local_rank') else 0
    world_size = int(os.environ.get('WORLD_SIZE', '8'))
    rank = int(os.environ.get('RANK', '0'))
    
    print(f"ğŸ”§ åˆ†å¸ƒå¼å‚æ•°: local_rank={local_rank}, world_size={world_size}, rank={rank}")
    
    # ğŸ”§ å®‰å…¨çš„ GCU è®¾å¤‡åˆå§‹åŒ–
    if torch_gcu_available and torch_gcu is not None:
        try:
            # è®¾ç½®å½“å‰è®¾å¤‡ä¸ºlocal_rankå¯¹åº”çš„GCUè®¾å¤‡
            torch_gcu.set_device(local_rank)
            device = torch_gcu.current_device()
            print(f"ğŸ”§ è®¾ç½®GCUè®¾å¤‡: gcu:{device} (local_rank: {local_rank})")
            
            # å»¶è¿Ÿæ¨¡å‹ç§»åŠ¨ï¼Œå…ˆè®© GCU å®Œå…¨åˆå§‹åŒ–
            print("ğŸ”§ ç­‰å¾… GCU Context å®Œå…¨åˆå§‹åŒ–...")
            torch_gcu.synchronize()
            
            # ç°åœ¨å®‰å…¨åœ°ç§»åŠ¨æ¨¡å‹ - ä½¿ç”¨.gcu()æ–¹æ³•
            model = model.gcu(device)
            device_name = f'gcu:{device}'
            print(f"âœ… æ¨¡å‹å·²å®‰å…¨ç§»åŠ¨åˆ° GCU è®¾å¤‡: {device_name}")
            print(f"ğŸ”§ æ¨¡å‹è®¾å¤‡: {next(model.parameters()).device}")
            
        except Exception as e:
            print(f"âš ï¸ GCU åˆå§‹åŒ–å¤±è´¥: {e}")
            print("ğŸ”§ é™çº§åˆ° CPU æ¨¡å¼...")
            model = model.to('cpu')
            device_name = 'cpu'
    else:
        model = model.to('cpu')
        device_name = 'cpu'
        print("âš ï¸ ä½¿ç”¨ CPU è®¾å¤‡")
    
    # ğŸ”§ åˆå§‹åŒ–åˆ†å¸ƒå¼åç«¯ - è®© torch.distributed.launch å¤„ç†
    print("ğŸ”§ åˆ†å¸ƒå¼åç«¯ç”± torch.distributed.launch è‡ªåŠ¨åˆå§‹åŒ– (ä½¿ç”¨ ECCL)")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    from torch.utils.data import DataLoader
    
    # ğŸ”§ å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶ä½¿ç”¨ MMEngine çš„ pseudo_collate æ¥å¤„ç† SegDataSample å¯¹è±¡
    # è¿™è§£å†³äº† RecursionError: maximum recursion depth exceeded çš„é—®é¢˜
    if not collate:
        raise RuntimeError("MMEngine pseudo_collate is required but not available. Please install MMEngine.")
    
    dataloader = DataLoader(
        dataset,
        batch_size=deepspeed_config.get('train_micro_batch_size_per_gpu', 2),
        shuffle=True,
        collate_fn=collate,  # ğŸ”§ ä½¿ç”¨ MMEngine çš„ pseudo_collate å¤„ç†ç°ä»£ SegDataSample å¯¹è±¡
        num_workers=4
    )
    
    # ğŸ”§ åˆå§‹åŒ–DeepSpeed - æ‰‹åŠ¨åˆ›å»ºä¼˜åŒ–å™¨é¿å…FusedAdamç¼–è¯‘é—®é¢˜
    # è¿™æ˜¯è§£å†³ IndexError: list index out of range çš„æœ€ç»ˆæ–¹æ¡ˆ
    # é€šè¿‡æ‰‹åŠ¨åˆ›å»ºæ ‡å‡†PyTorchä¼˜åŒ–å™¨ï¼Œç»•è¿‡DeepSpeedå†…éƒ¨çš„CUDAç‰¹å®šä»£ç è·¯å¾„
    print("ğŸ”§ æ­£åœ¨æ‰‹åŠ¨åˆ›å»ºä¼˜åŒ–å™¨ï¼Œç¡®ä¿GCUå…¼å®¹æ€§...")
    
    # ğŸ”§ å…³é”®ä¿®æ­£ (1/2): ä»é…ç½®ä¸­è·å–ä¼˜åŒ–å™¨å‚æ•°å¹¶æ‰‹åŠ¨åˆ›å»º
    optimizer_params = deepspeed_config.get('optimizer', {}).get('params', {})
    optimizer = torch.optim.AdamW(model.parameters(), **optimizer_params)
    print(f"âœ… æ‰‹åŠ¨åˆ›å»ºä¼˜åŒ–å™¨æˆåŠŸ: {type(optimizer).__name__}")
    
    print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–DeepSpeedï¼Œä½¿ç”¨æ‰‹åŠ¨åˆ›å»ºçš„ä¼˜åŒ–å™¨...")
    
    try:
        # ğŸ”§ å…³é”®ä¿®æ­£: ä½¿ç”¨ç‡§åŸå®˜æ–¹æ¨èçš„DeepSpeedåˆå§‹åŒ–æ–¹å¼
        print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–DeepSpeedå¼•æ“...")
        
        model_engine, optimizer, _, _ = deepspeed.initialize(
            model=model,
            model_parameters=model.parameters(),
            optimizer=optimizer,  # ä½¿ç”¨æ‰‹åŠ¨åˆ›å»ºçš„ä¼˜åŒ–å™¨ï¼Œé¿å…FusedAdamç¼–è¯‘é—®é¢˜
            config=deepspeed_config,
            dist_init_required=False  # é‡è¦ï¼šç”±äºtorch.distributed.launchå·²ç»åˆå§‹åŒ–äº†åˆ†å¸ƒå¼ï¼Œè¿™é‡Œè®¾ä¸ºFalse
        )
        print("âœ… DeepSpeed å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        
        # éªŒè¯è®¾å¤‡
        print(f"ğŸ”§ æ¨¡å‹è®¾å¤‡: {next(model_engine.parameters()).device}")
        
    except Exception as e:
        print(f"âŒ DeepSpeed åˆå§‹åŒ–å¤±è´¥: {e}")
        print("ğŸ”§ å°è¯•é™çº§åˆ°å•å¡è®­ç»ƒæ¨¡å¼...")
        
        # é™çº§åˆ°å•å¡è®­ç»ƒ
        optimizer = torch.optim.AdamW(model.parameters(), **optimizer_params)
        model_engine = model  # ç›´æ¥ä½¿ç”¨æ¨¡å‹ï¼Œä¸ä½¿ç”¨ DeepSpeed åŒ…è£…
        print("âœ… é™çº§åˆ°å•å¡è®­ç»ƒæ¨¡å¼æˆåŠŸ")
    
    print("è®­ç»ƒå¼€å§‹...")
    
    # --- ç®€åŒ–åçš„è®­ç»ƒå¾ªç¯ ---
    # ç”±äºé…ç½®æ–‡ä»¶ä¸­çš„æ•°æ®æµæ°´çº¿å·²ç»ä¿è¯äº†è¾“å‡ºæ ¼å¼çš„æ­£ç¡®æ€§ï¼Œ
    # ç°åœ¨å¯ä»¥æå¤§åœ°ç®€åŒ–è®­ç»ƒå¾ªç¯ä¸­çš„æ•°æ®å¤„ç†ä»£ç 
    for step, batch in enumerate(dataloader):
        if step >= 10:  # é™åˆ¶æ­¥æ•°ç”¨äºæµ‹è¯•
            break
        
        # 1. ä»æ‰¹æ¬¡ä¸­è§£åŒ…æ•°æ®
        #    MMEngineçš„pseudo_collateå’ŒPackSegInputsç¡®ä¿äº†è¿™é‡Œçš„æ ¼å¼æ˜¯å›ºå®šçš„
        inputs = batch['inputs'].to(model_engine.device)
        data_samples = [s.to(model_engine.device) for s in batch['data_samples']]

        # 2. ç›´æ¥è°ƒç”¨æ¨¡å‹
        #    MMEngineçš„æ¨¡å‹ä¼šè‡ªåŠ¨å¤„ç† inputs å’Œ data_samples
        loss_dict = model_engine(inputs, data_samples, mode='loss')
        loss = loss_dict['loss'] if isinstance(loss_dict, dict) else loss_dict
        
        # 3. åå‘ä¼ æ’­å’Œä¼˜åŒ–
        model_engine.backward(loss)
        model_engine.step()
        
        if step % 5 == 0:
            loss_value = loss.item() if hasattr(loss, 'item') else loss
            print(f"Step {step}, Loss: {loss_value}")
    
    print("è®­ç»ƒå®Œæˆ")


if __name__ == '__main__':
    main()
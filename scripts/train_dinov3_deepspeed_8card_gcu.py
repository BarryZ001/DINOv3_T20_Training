#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DINOv3 8å¡åˆ†å¸ƒå¼è®­ç»ƒè„šæœ¬ (v2.0 - ç”Ÿäº§ç‰ˆ)
ä½¿ç”¨ MMEngine æ„å»ºç»„ä»¶ï¼Œç”± DeepSpeed é©±åŠ¨è®­ç»ƒ
"""
import argparse
import json
import os
import sys
from pathlib import Path

# --- ç¯å¢ƒä¸åº“å¯¼å…¥ ---
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
os.environ.setdefault('PYTORCH_GCU_ALLOC_CONF', 'backend:topsMallocAsync')

import torch
import torch_gcu
import deepspeed
from mmengine.config import Config
from mmengine.registry import MODELS, DATASETS
from mmengine.dataset import pseudo_collate as collate  # ä½¿ç”¨æ­£ç¡®çš„collateå‡½æ•°

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
import mmseg_custom.models
import mmseg_custom.datasets
import mmseg_custom.transforms


def build_components(cfg, device_name):
    """æ ¹æ®é…ç½®æ„å»ºæ¨¡å‹å’Œæ•°æ®é›†"""
    print(f"ğŸ“Š æ„å»ºæ•°æ®é›†: {cfg.train_dataloader.dataset.type}")
    train_dataset = DATASETS.build(cfg.train_dataloader.dataset)
    print(f"âœ… è®­ç»ƒæ•°æ®é›†å¤§å°: {len(train_dataset)}")
    
    print(f"ğŸ—ï¸ æ„å»ºæ¨¡å‹: {cfg.model.type}")
    model = MODELS.build(cfg.model)
    model = model.to(device_name)
    print(f"âœ… æ¨¡å‹å·²ç§»åŠ¨åˆ°è®¾å¤‡: {device_name}")
    
    return model, train_dataset


def main():
    parser = argparse.ArgumentParser(description='DINOv3 8å¡åˆ†å¸ƒå¼è®­ç»ƒ (MMEngine + DeepSpeed)')
    parser.add_argument('config', help='è®­ç»ƒé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--work-dir', help='å·¥ä½œç›®å½•ï¼Œè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®')
    parser.add_argument('--local_rank', type=int, default=-1, help='DeepSpeedè‡ªåŠ¨æ³¨å…¥çš„å‚æ•°')
    args = parser.parse_args()

    # --- 1. ç¯å¢ƒè®¾ç½® ---
    local_rank = args.local_rank
    device_name = f"xla:{local_rank}"
    torch_gcu.set_device(local_rank)
    print(f"[Rank {local_rank}] ç¯å¢ƒè®¾ç½®å®Œæ¯•ï¼Œç›®æ ‡è®¾å¤‡: {device_name}")

    # --- 2. åŠ è½½MMEngineé…ç½® ---
    cfg = Config.fromfile(args.config)
    if args.work_dir:
        cfg.work_dir = args.work_dir
    os.makedirs(cfg.work_dir, exist_ok=True)
    
    # å°†DeepSpeedé…ç½®å†™å…¥ä¸´æ—¶JSONæ–‡ä»¶
    ds_config_path = os.path.join(cfg.work_dir, 'ds_config.json')
    with open(ds_config_path, 'w') as f:
        json.dump(cfg.deepspeed_config, f, indent=2)
    print(f"ğŸ“ DeepSpeed é…ç½®æ–‡ä»¶å·²ç”Ÿæˆ: {ds_config_path}")

    # --- 3. æ„å»ºæ¨¡å‹å’Œæ•°æ®é›† ---
    model, train_dataset = build_components(cfg, device_name)

    # --- 4. åˆå§‹åŒ–DeepSpeed ---
    print("ğŸ”§ åˆå§‹åŒ–DeepSpeedå¼•æ“...")
    engine, _, train_dataloader, _ = deepspeed.initialize(
        config=ds_config_path,
        model=model,
        model_parameters=model.parameters(),
        training_data=train_dataset,
        collate_fn=collate
    )
    print("âœ… DeepSpeedå¼•æ“åˆå§‹åŒ–å®Œæˆ")

    # --- 5. è®­ç»ƒå¾ªç¯ ---
    print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
    max_iters = cfg.train_cfg.max_iters
    
    for step, batch in enumerate(train_dataloader):
        if step >= max_iters:
            break
        
        # MMEngine æ¨¡å‹æœŸæœ›çš„è¾“å…¥æ ¼å¼æ˜¯ (inputs, data_samples, mode)
        inputs = batch['inputs'].to(engine.device)
        data_samples = [s.to(engine.device) for s in batch['data_samples']]

        # å‰å‘+åå‘+æ›´æ–°
        loss = engine(inputs, data_samples, mode='loss')['loss']
        engine.backward(loss)
        engine.step()

        if local_rank == 0 and step % cfg.deepspeed_config.get("steps_per_print", 50) == 0:
            print(f"[Rank {local_rank}] Step={step}/{max_iters}  Loss={loss.item():.4f}")

    # --- 6. ä¿å­˜æ¨¡å‹ ---
    # DeepSpeedçš„ `save_checkpoint` ä¼šè‡ªåŠ¨å¤„ç†åŒæ­¥ï¼Œç¡®ä¿åªåœ¨rank 0ä¸Šæ‰§è¡ŒIOæ“ä½œ
    engine.save_checkpoint(cfg.work_dir, tag=f"step_{max_iters}")
    print(f"ğŸ’¾ DeepSpeed Checkpoint å·²ä¿å­˜è‡³: {cfg.work_dir}")

    print(f"[Rank {local_rank}] è®­ç»ƒå®Œæˆ!")


if __name__ == '__main__':
    main()
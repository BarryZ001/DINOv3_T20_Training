#!/usr/bin/env python3
"""
ç‡§åŸT20 DeepSpeedè®­ç»ƒè„šæœ¬ (ç”Ÿäº§ç‰ˆ)
ä½¿ç”¨MMEngineæ„å»ºç»„ä»¶ï¼ŒDeepSpeedé©±åŠ¨è®­ç»ƒ
"""

import argparse
import json
import os
import sys
from pathlib import Path
from typing import Optional, Any

# é¡¹ç›®è·¯å¾„é…ç½®
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
os.environ.setdefault('PYTORCH_GCU_ALLOC_CONF', 'backend:topsMallocAsync')

import torch
import numpy as np
from torch.utils.data.dataloader import default_collate

# æ¡ä»¶å¯¼å…¥æ¨¡å—ï¼Œé¿å…åœ¨å¼€å‘ç¯å¢ƒä¸­çš„å¯¼å…¥é”™è¯¯
torch_gcu_available = False
deepspeed_available = False
mmengine_available = False

# ç±»å‹æ³¨è§£å˜é‡
Config: Optional[Any] = None
MODELS: Optional[Any] = None
DATASETS: Optional[Any] = None
collate: Optional[Any] = None
torch_gcu: Optional[Any] = None
deepspeed: Optional[Any] = None

try:
    import torch_gcu  # type: ignore
    torch_gcu_available = True
except ImportError:
    torch_gcu = None

try:
    import deepspeed  # type: ignore
    deepspeed_available = True
except ImportError:
    deepspeed = None

try:
    from mmengine.config import Config  # type: ignore
    from mmengine.registry import MODELS, DATASETS  # type: ignore
    from mmengine.dataset import pseudo_collate as collate  # type: ignore
    mmengine_available = True
except ImportError:
    Config = None
    MODELS = None
    DATASETS = None
    collate = None

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—ï¼ˆä»…åœ¨MMEngineå¯ç”¨æ—¶ï¼‰
if mmengine_available:
    try:
        import mmseg_custom.models  # type: ignore
        import mmseg_custom.datasets  # type: ignore
        import mmseg_custom.transforms  # type: ignore
    except ImportError:
        pass


# ğŸ”§ æ³¨é‡Šæ‰è‡ªå®šä¹‰ collate å‡½æ•°ï¼Œç°åœ¨ä½¿ç”¨ MMEngine çš„ pseudo_collate
# è¿™ä¸ªå‡½æ•°ä¹‹å‰ç”¨äºå¤„ç† numpy åˆ° tensor çš„è½¬æ¢å’Œ paddingï¼Œ
# ä½†ç°åœ¨æ•°æ®ç®¡é“å·²ç»ä½¿ç”¨ PackSegInputs äº§ç”Ÿæ ‡å‡†çš„ SegDataSample å¯¹è±¡ï¼Œ
# åº”è¯¥ä½¿ç”¨ MMEngine çš„ pseudo_collate æ¥é¿å… RecursionError

# def mmseg_collate_fn(batch, pad_value=0):
#     """
#     mmsegmentation-style collate_fn:
#     - è‡ªåŠ¨æŠŠ numpy è½¬ torch.Tensor
#     - è‡ªåŠ¨ pad ä¿è¯ batch å†…å›¾åƒå°ºå¯¸ä¸€è‡´
#     - ä¿æŒ dict ç»“æ„ (inputs / gt_semantic_seg)
#     """
#     # ... (åŸæœ‰å®ç°å·²æ³¨é‡Š)
#     pass


def build_components(cfg: Any, device_name: str) -> tuple:
    """æ„å»ºè®­ç»ƒç»„ä»¶"""
    if not mmengine_available or DATASETS is None or MODELS is None:
        raise RuntimeError("MMEngine not available")
    
    # æ„å»ºæ•°æ®é›†
    dataset = DATASETS.build(cfg.train_dataloader.dataset)
    
    # æ„å»ºæ¨¡å‹
    model = MODELS.build(cfg.model)
    
    # è®¾ç½®è®¾å¤‡ - ç›´æ¥ä½¿ç”¨device_nameå­—ç¬¦ä¸²ï¼Œå…¼å®¹MMEngineçš„.to()æ–¹æ³•
    model = model.to(device_name)
    
    return model, dataset


def main() -> None:
    """ä¸»è®­ç»ƒå‡½æ•°"""
    # ğŸ”§ å¼ºåŒ–ç‰ˆGCUå…¼å®¹æ€§è®¾ç½® - å½»åº•ç¦ç”¨æ‰€æœ‰CUDAç‰¹å®šåŠŸèƒ½
    # è¿™æ˜¯è§£å†³IndexError: list index out of rangeçš„å…³é”®ç¯å¢ƒå˜é‡è®¾ç½®
    
    # DeepSpeed CUDAç‰¹å®šç»„ä»¶ç¦ç”¨
    os.environ['DEEPSPEED_DISABLE_FUSED_ADAM'] = '1'
    os.environ['DS_BUILD_FUSED_ADAM'] = '0'
    os.environ['DS_BUILD_CPU_ADAM'] = '1'  # å¼ºåˆ¶ä½¿ç”¨CPUç‰ˆæœ¬çš„Adam
    os.environ['DS_BUILD_UTILS'] = '0'  # ç¦ç”¨å…¶ä»–CUDAç‰¹å®šå·¥å…·
    os.environ['DS_BUILD_AIO'] = '0'  # ç¦ç”¨å¼‚æ­¥IOï¼ˆå¯èƒ½ä¾èµ–CUDAï¼‰
    os.environ['DS_BUILD_SPARSE_ATTN'] = '0'  # ç¦ç”¨ç¨€ç–æ³¨æ„åŠ›ï¼ˆCUDAç‰¹å®šï¼‰
    
    # é¢å¤–çš„CUDAç‰¹å®šåŠŸèƒ½ç¦ç”¨
    os.environ['DS_BUILD_FUSED_LAMB'] = '0'  # ç¦ç”¨FusedLambä¼˜åŒ–å™¨
    os.environ['DS_BUILD_TRANSFORMER'] = '0'  # ç¦ç”¨CUDA Transformerå†…æ ¸
    os.environ['DS_BUILD_STOCHASTIC_TRANSFORMER'] = '0'  # ç¦ç”¨éšæœºTransformer
    os.environ['DS_BUILD_TRANSFORMER_INFERENCE'] = '0'  # ç¦ç”¨Transformeræ¨ç†å†…æ ¸
    os.environ['DS_BUILD_QUANTIZER'] = '0'  # ç¦ç”¨é‡åŒ–å™¨ï¼ˆå¯èƒ½ä¾èµ–CUDAï¼‰
    os.environ['DS_BUILD_RANDOM_LTD'] = '0'  # ç¦ç”¨éšæœºLTD
    
    # PyTorch CUDAç›¸å…³è®¾ç½®
    os.environ['CUDA_VISIBLE_DEVICES'] = ''  # éšè—CUDAè®¾å¤‡
    os.environ['TORCH_CUDA_ARCH_LIST'] = ''  # æ¸…ç©ºCUDAæ¶æ„åˆ—è¡¨
    
    # å¼ºåˆ¶ä½¿ç”¨CPUåç«¯è¿›è¡ŒæŸäº›æ“ä½œ
    os.environ['OMP_NUM_THREADS'] = '4'  # é™åˆ¶OpenMPçº¿ç¨‹æ•°
    
    parser = argparse.ArgumentParser(description='DeepSpeed Training')
    parser.add_argument('--config', required=True, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--work-dir', required=True, help='å·¥ä½œç›®å½•')
    parser.add_argument('--deepspeed', required=True, help='DeepSpeedé…ç½®æ–‡ä»¶')
    parser.add_argument('--launcher', default='deepspeed', help='å¯åŠ¨å™¨ç±»å‹')
    parser.add_argument('--local_rank', type=int, default=0, help='æœ¬åœ°rank')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥å¿…è¦æ¨¡å—
    if not mmengine_available or Config is None:
        print("Error: MMEngine not available")
        return
    
    if not deepspeed_available or deepspeed is None:
        print("Error: DeepSpeed not available")
        return
    
    print(f"ğŸ”§ å·²è®¾ç½®ç¯å¢ƒå˜é‡ç¦ç”¨FusedAdamå’Œå…¶ä»–CUDAç‰¹å®šç»„ä»¶ï¼Œç¡®ä¿GCUå…¼å®¹æ€§")
    
    # åŠ è½½é…ç½®
    cfg = Config.fromfile(args.config)
    
    # ç¯å¢ƒè®¾ç½® - ä½¿ç”¨xlaè®¾å¤‡æ ¼å¼ä»¥å…¼å®¹MMEngine
    if torch_gcu_available and torch_gcu is not None:
        device_id = torch_gcu.current_device()
        device_name = f'xla:{device_id}'
    else:
        device_name = 'cuda'
    
    # æ„å»ºç»„ä»¶
    model, dataset = build_components(cfg, device_name)
    
    # åŠ è½½DeepSpeedé…ç½®
    with open(args.deepspeed, 'r') as f:
        deepspeed_config = json.load(f)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    from torch.utils.data import DataLoader
    
    # ğŸ”§ å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶ä½¿ç”¨ MMEngine çš„ pseudo_collate æ¥å¤„ç† SegDataSample å¯¹è±¡
    # è¿™è§£å†³äº† RecursionError: maximum recursion depth exceeded çš„é—®é¢˜
    if not collate:
        raise RuntimeError("MMEngine pseudo_collate is required but not available. Please install MMEngine.")
    
    dataloader = DataLoader(
        dataset,
        batch_size=deepspeed_config.get('train_micro_batch_size_per_gpu', 8),
        shuffle=True,
        collate_fn=collate,  # ğŸ”§ ä½¿ç”¨ MMEngine çš„ pseudo_collate å¤„ç†ç°ä»£ SegDataSample å¯¹è±¡
        num_workers=4
    )
    
    # ğŸ”§ åˆå§‹åŒ–DeepSpeed - æ‰‹åŠ¨åˆ›å»ºä¼˜åŒ–å™¨é¿å…FusedAdamç¼–è¯‘é—®é¢˜
    # è¿™æ˜¯è§£å†³ IndexError: list index out of range çš„æœ€ç»ˆæ–¹æ¡ˆ
    # é€šè¿‡æ‰‹åŠ¨åˆ›å»ºæ ‡å‡†PyTorchä¼˜åŒ–å™¨ï¼Œç»•è¿‡DeepSpeedå†…éƒ¨çš„CUDAç‰¹å®šä»£ç è·¯å¾„
    print("ğŸ”§ æ­£åœ¨æ‰‹åŠ¨åˆ›å»ºä¼˜åŒ–å™¨ï¼Œç¡®ä¿GCUå…¼å®¹æ€§...")
    
    # ğŸ”§ å…³é”®ä¿®æ­£ (1/2): ä»é…ç½®ä¸­è·å–ä¼˜åŒ–å™¨å‚æ•°å¹¶æ‰‹åŠ¨åˆ›å»º
    optimizer_params = deepspeed_config.get('optimizer', {}).get('params', {})
    optimizer = torch.optim.AdamW(model.parameters(), **optimizer_params)
    print(f"âœ… æ‰‹åŠ¨åˆ›å»ºä¼˜åŒ–å™¨æˆåŠŸ: {type(optimizer).__name__}")
    
    print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–DeepSpeedï¼Œä½¿ç”¨æ‰‹åŠ¨åˆ›å»ºçš„ä¼˜åŒ–å™¨...")
    
    # ğŸ”§ å…³é”®ä¿®æ­£ (2/2): å°†æ‰‹åŠ¨åˆ›å»ºçš„optimizerå®ä¾‹ä¼ é€’ç»™initializeå‡½æ•°
    # è¿™é¿å…äº†DeepSpeedå†…éƒ¨å°è¯•ç¼–è¯‘FusedAdamçš„é—®é¢˜
    model_engine, optimizer, _, _ = deepspeed.initialize(
        model=model,
        model_parameters=model.parameters(),  # å…³é”®ï¼šæä¾›æ¨¡å‹å‚æ•°ç»™DeepSpeed
        optimizer=optimizer,  # ğŸ”§ å…³é”®ï¼šä¼ å…¥æ‰‹åŠ¨åˆ›å»ºçš„ä¼˜åŒ–å™¨
        config=deepspeed_config
    )
    
    print("DeepSpeedè®­ç»ƒå¼€å§‹...")
    
    # ğŸ”¥ ä¿®å¤çš„è®­ç»ƒå¾ªç¯ - æ­£ç¡®å¤„ç†æ‰¹æ¬¡æ•°æ®æ ¼å¼
    for step, batch in enumerate(dataloader):
        if step >= 10:  # é™åˆ¶æ­¥æ•°ç”¨äºæµ‹è¯•
            break
        
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ­£ç¡®æå–å’Œå¤„ç†æ‰¹æ¬¡æ•°æ®
        if step == 0:
            print(f"ğŸ” è°ƒè¯•ä¿¡æ¯ - Batch ç»“æ„: {type(batch)}")
            if isinstance(batch, dict):
                print(f"ğŸ” Batch keys: {list(batch.keys())}")
                if 'inputs' in batch:
                    print(f"ğŸ” inputs å½¢çŠ¶: {batch['inputs'].shape if hasattr(batch['inputs'], 'shape') else type(batch['inputs'])}")
                if 'data_samples' in batch:
                    print(f"ğŸ” data_samples ç±»å‹: {type(batch['data_samples'])}")
        
        # ğŸ”§ ç°åœ¨ä½¿ç”¨ MMEngine çš„ pseudo_collateï¼Œbatch åº”è¯¥ç›´æ¥åŒ…å« inputs å’Œ data_samples
        # ä¸å†éœ€è¦å¤æ‚çš„æ‰‹åŠ¨å¤„ç†é€»è¾‘
        
        # ä» batch ä¸­æå– inputs å’Œ data_samples
        if isinstance(batch, dict):
            inputs = batch.get('inputs')
            data_samples = batch.get('data_samples')
        else:
            # å¦‚æœ batch æ˜¯ listï¼Œè¯´æ˜æ˜¯ pseudo_collate çš„ç»“æœ
            inputs = batch[0] if len(batch) > 0 else None
            data_samples = batch[1] if len(batch) > 1 else None
        
        if inputs is None:
            print("[ERROR] No inputs found in batch")
            continue
            
        print(f"[DEBUG] inputs type: {type(inputs)}, shape: {getattr(inputs, 'shape', 'N/A')}")
        print(f"[DEBUG] data_samples type: {type(data_samples)}")
        
        # ç¡®ä¿ inputs æ˜¯æ­£ç¡®çš„å¼ é‡æ ¼å¼
        if isinstance(inputs, list):
            inputs = torch.stack(inputs)
        elif not isinstance(inputs, torch.Tensor):
            print(f"[ERROR] Unexpected inputs type: {type(inputs)}")
            continue
            
        # å¦‚æœæ˜¯å•å¼ å›¾åƒï¼Œæ·»åŠ  batch ç»´åº¦
        if inputs.dim() == 3:
            print("[DEBUG] single image tensor, unsqueezing batch dim...")
            inputs = inputs.unsqueeze(0)
            print(f"[DEBUG] after unsqueeze: {inputs.shape}")
        
        # ğŸ”§ æ··åˆç²¾åº¦ä¿®å¤ï¼šä½¿ç”¨æ¨¡å‹å‚æ•°çš„çœŸå® device å’Œ dtype
        device = next(model_engine.parameters()).device
        dtype = next(model_engine.parameters()).dtype
        
        # ğŸ”§ T20 å†…å­˜å®‰å…¨ä¿®å¤ï¼šåˆ†æ­¥éª¤è¿›è¡Œè®¾å¤‡è½¬æ¢
        print(f"[DEBUG] Converting inputs to device: {device}, dtype: {dtype}")
        
        # å…ˆç¡®ä¿å¼ é‡åœ¨ CPU ä¸Šä¸”å†…å­˜è¿ç»­
        if inputs.device != torch.device('cpu'):
            inputs = inputs.cpu().contiguous()
        
        # åˆ†æ­¥è½¬æ¢ï¼šå…ˆè½¬æ¢æ•°æ®ç±»å‹ï¼Œå†è½¬æ¢è®¾å¤‡
        if inputs.dtype != dtype:
            inputs = inputs.to(dtype=dtype)
        
        if inputs.device != device:
            inputs = inputs.to(device=device, non_blocking=False)
        
        print(f"[DEBUG] final inputs shape: {inputs.shape}, device: {inputs.device}, dtype: {inputs.dtype}")
        
        # ğŸ”§ ä½¿ç”¨ MMEngine çš„æ ‡å‡†æ ¼å¼è°ƒç”¨æ¨¡å‹
        # data_samples åº”è¯¥å·²ç»ç”± pseudo_collate æ­£ç¡®å¤„ç†
        if data_samples is not None:
            # ç¡®ä¿ data_samples ä¹Ÿåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            if hasattr(data_samples, 'to'):
                data_samples = data_samples.to(device)
            elif isinstance(data_samples, list):
                for i, sample in enumerate(data_samples):
                    if hasattr(sample, 'to'):
                        data_samples[i] = sample.to(device)
                    elif hasattr(sample, 'gt_sem_seg') and hasattr(sample.gt_sem_seg, 'data'):
                        sample.gt_sem_seg.data = sample.gt_sem_seg.data.to(device)
            
            # è°ƒç”¨æ¨¡å‹çš„ forward æ–¹æ³•
            loss_dict = model_engine(inputs, data_samples, mode='loss')
            
            # å¤„ç†è¿”å›çš„ loss
            if isinstance(loss_dict, dict):
                loss = loss_dict.get('loss', loss_dict.get('decode.loss_ce', list(loss_dict.values())[0]))
            else:
                loss = loss_dict
        else:
            # å…œåº•å¤„ç†ï¼šç›´æ¥ä¼ é€’ inputs
            print(f"âš ï¸ è­¦å‘Šï¼šdata_samplesä¸ºNoneï¼Œç›´æ¥ä¼ é€’inputs")
            loss = model_engine(inputs)
        
        model_engine.backward(loss)
        model_engine.step()
        
        if step % 5 == 0:
            loss_value = loss.item() if hasattr(loss, 'item') else loss
            print(f"Step {step}, Loss: {loss_value}")
    
    print("è®­ç»ƒå®Œæˆ")


if __name__ == '__main__':
    main()
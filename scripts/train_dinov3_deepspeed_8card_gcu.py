#!/usr/bin/env python3
"""
ç‡§åŸT20 DeepSpeedè®­ç»ƒè„šæœ¬ (ç”Ÿäº§ç‰ˆ)
ä½¿ç”¨MMEngineæ„å»ºç»„ä»¶ï¼ŒDeepSpeedé©±åŠ¨è®­ç»ƒ
"""

import argparse
import json
import os
import sys
from pathlib import Path
from typing import Optional, Any

# é¡¹ç›®è·¯å¾„é…ç½®
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
os.environ.setdefault('PYTORCH_GCU_ALLOC_CONF', 'backend:topsMallocAsync')

import torch

# æ¡ä»¶å¯¼å…¥æ¨¡å—ï¼Œé¿å…åœ¨å¼€å‘ç¯å¢ƒä¸­çš„å¯¼å…¥é”™è¯¯
torch_gcu_available = False
deepspeed_available = False
mmengine_available = False

# ç±»å‹æ³¨è§£å˜é‡
Config: Optional[Any] = None
MODELS: Optional[Any] = None
DATASETS: Optional[Any] = None
collate: Optional[Any] = None
torch_gcu: Optional[Any] = None
deepspeed: Optional[Any] = None

try:
    import torch_gcu  # type: ignore
    torch_gcu_available = True
except ImportError:
    torch_gcu = None

try:
    import deepspeed  # type: ignore
    deepspeed_available = True
except ImportError:
    deepspeed = None

try:
    from mmengine.config import Config  # type: ignore
    from mmengine.registry import MODELS, DATASETS  # type: ignore
    from mmengine.dataset import pseudo_collate as collate  # type: ignore
    mmengine_available = True
except ImportError:
    Config = None
    MODELS = None
    DATASETS = None
    collate = None

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—ï¼ˆä»…åœ¨MMEngineå¯ç”¨æ—¶ï¼‰
if mmengine_available:
    try:
        import mmseg_custom.models  # type: ignore
        import mmseg_custom.datasets  # type: ignore
        import mmseg_custom.transforms  # type: ignore
    except ImportError:
        pass


def build_components(cfg: Any, device_name: str) -> tuple:
    """æ„å»ºè®­ç»ƒç»„ä»¶"""
    if not mmengine_available or DATASETS is None or MODELS is None:
        raise RuntimeError("MMEngine not available")
    
    # æ„å»ºæ•°æ®é›†
    dataset = DATASETS.build(cfg.train_dataloader.dataset)
    
    # æ„å»ºæ¨¡å‹
    model = MODELS.build(cfg.model)
    
    # è®¾ç½®è®¾å¤‡ - ç›´æ¥ä½¿ç”¨device_nameå­—ç¬¦ä¸²ï¼Œå…¼å®¹MMEngineçš„.to()æ–¹æ³•
    model = model.to(device_name)
    
    return model, dataset


def main() -> None:
    """ä¸»è®­ç»ƒå‡½æ•°"""
    # ğŸ”§ å¼ºåŒ–ç‰ˆGCUå…¼å®¹æ€§è®¾ç½® - å½»åº•ç¦ç”¨æ‰€æœ‰CUDAç‰¹å®šåŠŸèƒ½
    # è¿™æ˜¯è§£å†³IndexError: list index out of rangeçš„å…³é”®ç¯å¢ƒå˜é‡è®¾ç½®
    
    # DeepSpeed CUDAç‰¹å®šç»„ä»¶ç¦ç”¨
    os.environ['DEEPSPEED_DISABLE_FUSED_ADAM'] = '1'
    os.environ['DS_BUILD_FUSED_ADAM'] = '0'
    os.environ['DS_BUILD_CPU_ADAM'] = '1'  # å¼ºåˆ¶ä½¿ç”¨CPUç‰ˆæœ¬çš„Adam
    os.environ['DS_BUILD_UTILS'] = '0'  # ç¦ç”¨å…¶ä»–CUDAç‰¹å®šå·¥å…·
    os.environ['DS_BUILD_AIO'] = '0'  # ç¦ç”¨å¼‚æ­¥IOï¼ˆå¯èƒ½ä¾èµ–CUDAï¼‰
    os.environ['DS_BUILD_SPARSE_ATTN'] = '0'  # ç¦ç”¨ç¨€ç–æ³¨æ„åŠ›ï¼ˆCUDAç‰¹å®šï¼‰
    
    # é¢å¤–çš„CUDAç‰¹å®šåŠŸèƒ½ç¦ç”¨
    os.environ['DS_BUILD_FUSED_LAMB'] = '0'  # ç¦ç”¨FusedLambä¼˜åŒ–å™¨
    os.environ['DS_BUILD_TRANSFORMER'] = '0'  # ç¦ç”¨CUDA Transformerå†…æ ¸
    os.environ['DS_BUILD_STOCHASTIC_TRANSFORMER'] = '0'  # ç¦ç”¨éšæœºTransformer
    os.environ['DS_BUILD_TRANSFORMER_INFERENCE'] = '0'  # ç¦ç”¨Transformeræ¨ç†å†…æ ¸
    os.environ['DS_BUILD_QUANTIZER'] = '0'  # ç¦ç”¨é‡åŒ–å™¨ï¼ˆå¯èƒ½ä¾èµ–CUDAï¼‰
    os.environ['DS_BUILD_RANDOM_LTD'] = '0'  # ç¦ç”¨éšæœºLTD
    
    # PyTorch CUDAç›¸å…³è®¾ç½®
    os.environ['CUDA_VISIBLE_DEVICES'] = ''  # éšè—CUDAè®¾å¤‡
    os.environ['TORCH_CUDA_ARCH_LIST'] = ''  # æ¸…ç©ºCUDAæ¶æ„åˆ—è¡¨
    
    # å¼ºåˆ¶ä½¿ç”¨CPUåç«¯è¿›è¡ŒæŸäº›æ“ä½œ
    os.environ['OMP_NUM_THREADS'] = '4'  # é™åˆ¶OpenMPçº¿ç¨‹æ•°
    
    parser = argparse.ArgumentParser(description='DeepSpeed Training')
    parser.add_argument('--config', required=True, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--work-dir', required=True, help='å·¥ä½œç›®å½•')
    parser.add_argument('--deepspeed', required=True, help='DeepSpeedé…ç½®æ–‡ä»¶')
    parser.add_argument('--launcher', default='deepspeed', help='å¯åŠ¨å™¨ç±»å‹')
    parser.add_argument('--local_rank', type=int, default=0, help='æœ¬åœ°rank')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥å¿…è¦æ¨¡å—
    if not mmengine_available or Config is None:
        print("Error: MMEngine not available")
        return
    
    if not deepspeed_available or deepspeed is None:
        print("Error: DeepSpeed not available")
        return
    
    print(f"ğŸ”§ å·²è®¾ç½®ç¯å¢ƒå˜é‡ç¦ç”¨FusedAdamå’Œå…¶ä»–CUDAç‰¹å®šç»„ä»¶ï¼Œç¡®ä¿GCUå…¼å®¹æ€§")
    
    # åŠ è½½é…ç½®
    cfg = Config.fromfile(args.config)
    
    # ç¯å¢ƒè®¾ç½® - ä½¿ç”¨xlaè®¾å¤‡æ ¼å¼ä»¥å…¼å®¹MMEngine
    if torch_gcu_available and torch_gcu is not None:
        device_id = torch_gcu.current_device()
        device_name = f'xla:{device_id}'
    else:
        device_name = 'cuda'
    
    # æ„å»ºç»„ä»¶
    model, dataset = build_components(cfg, device_name)
    
    # åŠ è½½DeepSpeedé…ç½®
    with open(args.deepspeed, 'r') as f:
        deepspeed_config = json.load(f)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    from torch.utils.data import DataLoader
    dataloader = DataLoader(
        dataset,
        batch_size=deepspeed_config.get('train_micro_batch_size_per_gpu', 8),
        shuffle=True,
        collate_fn=collate if collate else None,
        num_workers=4
    )
    
    # ğŸ”§ åˆå§‹åŒ–DeepSpeed - æ‰‹åŠ¨åˆ›å»ºä¼˜åŒ–å™¨é¿å…FusedAdamç¼–è¯‘é—®é¢˜
    # è¿™æ˜¯è§£å†³ IndexError: list index out of range çš„æœ€ç»ˆæ–¹æ¡ˆ
    # é€šè¿‡æ‰‹åŠ¨åˆ›å»ºæ ‡å‡†PyTorchä¼˜åŒ–å™¨ï¼Œç»•è¿‡DeepSpeedå†…éƒ¨çš„CUDAç‰¹å®šä»£ç è·¯å¾„
    print("ğŸ”§ æ­£åœ¨æ‰‹åŠ¨åˆ›å»ºä¼˜åŒ–å™¨ï¼Œç¡®ä¿GCUå…¼å®¹æ€§...")
    
    # ğŸ”§ å…³é”®ä¿®æ­£ (1/2): ä»é…ç½®ä¸­è·å–ä¼˜åŒ–å™¨å‚æ•°å¹¶æ‰‹åŠ¨åˆ›å»º
    optimizer_params = deepspeed_config.get('optimizer', {}).get('params', {})
    optimizer = torch.optim.AdamW(model.parameters(), **optimizer_params)
    print(f"âœ… æ‰‹åŠ¨åˆ›å»ºä¼˜åŒ–å™¨æˆåŠŸ: {type(optimizer).__name__}")
    
    print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–DeepSpeedï¼Œä½¿ç”¨æ‰‹åŠ¨åˆ›å»ºçš„ä¼˜åŒ–å™¨...")
    
    # ğŸ”§ å…³é”®ä¿®æ­£ (2/2): å°†æ‰‹åŠ¨åˆ›å»ºçš„optimizerå®ä¾‹ä¼ é€’ç»™initializeå‡½æ•°
    # è¿™é¿å…äº†DeepSpeedå†…éƒ¨å°è¯•ç¼–è¯‘FusedAdamçš„é—®é¢˜
    model_engine, optimizer, _, _ = deepspeed.initialize(
        model=model,
        model_parameters=model.parameters(),  # å…³é”®ï¼šæä¾›æ¨¡å‹å‚æ•°ç»™DeepSpeed
        optimizer=optimizer,  # ğŸ”§ å…³é”®ï¼šä¼ å…¥æ‰‹åŠ¨åˆ›å»ºçš„ä¼˜åŒ–å™¨
        config=deepspeed_config
    )
    
    print("DeepSpeedè®­ç»ƒå¼€å§‹...")
    
    # ğŸ”¥ ä¿®å¤çš„è®­ç»ƒå¾ªç¯ - æ­£ç¡®å¤„ç†æ‰¹æ¬¡æ•°æ®æ ¼å¼
    for step, batch in enumerate(dataloader):
        if step >= 10:  # é™åˆ¶æ­¥æ•°ç”¨äºæµ‹è¯•
            break
        
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ­£ç¡®æå–å’Œå¤„ç†æ‰¹æ¬¡æ•°æ®
        if step == 0:
            print(f"ğŸ” è°ƒè¯•ä¿¡æ¯ - Batch ç»“æ„: {type(batch)}")
            if isinstance(batch, dict):
                print(f"ğŸ” Batch keys: {list(batch.keys())}")
                if 'inputs' in batch:
                    print(f"ğŸ” inputs å½¢çŠ¶: {batch['inputs'].shape if hasattr(batch['inputs'], 'shape') else type(batch['inputs'])}")
                if 'data_samples' in batch:
                    print(f"ğŸ” data_samples ç±»å‹: {type(batch['data_samples'])}")
        
        # æ ¹æ® MMEngine æ ‡å‡†ï¼Œæ¨¡å‹æœŸæœ›æ¥æ”¶ inputs å’Œ data_samples
        if isinstance(batch, dict) and 'inputs' in batch:
            # æ ‡å‡† MMEngine æ ¼å¼
            inputs = batch['inputs']
            data_samples = batch.get('data_samples', None)
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šç¡®ä¿ inputs æ˜¯æ­£ç¡®çš„ 4D tensor (B, C, H, W)
            if isinstance(inputs, list):
                print(f"[DEBUG] inputs is list, stacking {len(inputs)} tensors...")
                inputs = torch.stack(inputs, dim=0)
                print(f"[DEBUG] after stacking: {inputs.shape}")
            elif isinstance(inputs, torch.Tensor) and inputs.dim() == 3:
                print("[DEBUG] single image tensor, unsqueezing batch dim...")
                inputs = inputs.unsqueeze(0)
                print(f"[DEBUG] after unsqueeze: {inputs.shape}")
            
            print(f"[DEBUG] final inputs shape: {inputs.shape}")
            
            # è°ƒç”¨æ¨¡å‹çš„ forward æ–¹æ³•
            loss_dict = model_engine(inputs, data_samples, mode='loss')
            
            # å¤„ç†è¿”å›çš„ loss
            if isinstance(loss_dict, dict):
                loss = loss_dict.get('loss', loss_dict.get('decode.loss_ce', list(loss_dict.values())[0]))
            else:
                loss = loss_dict
                
        else:
            # å…œåº•å¤„ç†ï¼šç›´æ¥ä¼ é€’æ•´ä¸ª batch
            print(f"âš ï¸ è­¦å‘Šï¼šä½¿ç”¨å…œåº•å¤„ç†ï¼Œç›´æ¥ä¼ é€’ batch")
            loss = model_engine(batch)
        
        model_engine.backward(loss)
        model_engine.step()
        
        if step % 5 == 0:
            loss_value = loss.item() if hasattr(loss, 'item') else loss
            print(f"Step {step}, Loss: {loss_value}")
    
    print("è®­ç»ƒå®Œæˆ")


if __name__ == '__main__':
    main()
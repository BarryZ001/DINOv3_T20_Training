#!/usr/bin/env python3
"""
æ•°æ®åŠ è½½è°ƒè¯•è„šæœ¬ - æœ¬åœ°ç‰ˆæœ¬
ç”¨äºè¯Šæ–­ RuntimeError: stack expects a non-empty TensorList é—®é¢˜
"""

import os
import sys
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__)))

import torch
from mmengine.config import Config
from mmengine.registry import MODELS, DATASETS
from torch.utils.data import DataLoader

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
import mmseg_custom.datasets
import mmseg_custom.transforms
import mmseg_custom.models

def debug_dataloader(config_path):
    """è°ƒè¯•æ•°æ®åŠ è½½å™¨"""
    print("ğŸ” === å¼€å§‹æ•°æ®åŠ è½½è°ƒè¯• ===")
    
    # 1. åŠ è½½é…ç½®
    cfg = Config.fromfile(config_path)
    print(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {config_path}")
    
    # 2. ä¿®æ”¹æ•°æ®è·¯å¾„ä¸ºæœ¬åœ°è·¯å¾„
    if hasattr(cfg, 'local_data_root'):
        cfg.train_dataloader.dataset.data_root = cfg.local_data_root
        print(f"ğŸ“ ä½¿ç”¨æœ¬åœ°æ•°æ®è·¯å¾„: {cfg.local_data_root}")
    
    # 3. æ„å»ºæ•°æ®é›†
    try:
        train_dataset = DATASETS.build(cfg.train_dataloader.dataset)
        print(f"âœ… æ•°æ®é›†æ„å»ºæˆåŠŸï¼Œæ ·æœ¬æ•°é‡: {len(train_dataset)}")
    except Exception as e:
        print(f"âŒ æ•°æ®é›†æ„å»ºå¤±è´¥: {e}")
        return
    
    # 4. åˆ›å»ºDataLoader
    from mmengine.dataset import pseudo_collate as collate
    
    debug_dataloader = DataLoader(
        train_dataset,
        batch_size=2,  # å°æ‰¹æ¬¡ç”¨äºè°ƒè¯•
        shuffle=True,
        num_workers=0,  # å•è¿›ç¨‹è°ƒè¯•
        collate_fn=collate
    )
    
    print(f"âœ… DataLoaderåˆ›å»ºæˆåŠŸ")
    
    # 5. è¿­ä»£æ£€æŸ¥æ‰¹æ¬¡
    for i, batch in enumerate(debug_dataloader):
        print(f"\n--- æ­£åœ¨æ£€æŸ¥ Batch #{i} ---")
        print(f"Batch keys: {list(batch.keys())}")
        
        if 'data_samples' not in batch:
            print("âŒ é”™è¯¯: æ‰¹å¤„ç†æ•°æ®ä¸­æ²¡æœ‰ 'data_samples' é”®ï¼")
            print(f"å®é™…çš„é”®: {list(batch.keys())}")
            continue
        
        print(f"Batch size: {len(batch['data_samples'])}")
        has_labels_count = 0
        
        for j, sample in enumerate(batch['data_samples']):
            print(f"  æ ·æœ¬ #{j}:")
            print(f"    ç±»å‹: {type(sample)}")
            
            # æ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„æ ‡ç­¾å­—æ®µ
            label_fields = ['gt_sem_seg', 'gt_semantic_seg', 'gt_seg_map']
            found_label = False
            
            for field in label_fields:
                if hasattr(sample, field):
                    label_data = getattr(sample, field)
                    if label_data is not None:
                        has_labels_count += 1
                        found_label = True
                        if hasattr(label_data, 'data'):
                            print(f"    âœ… æ‰¾åˆ°æ ‡ç­¾å­—æ®µ '{field}', å½¢çŠ¶: {label_data.data.shape}")
                        else:
                            print(f"    âœ… æ‰¾åˆ°æ ‡ç­¾å­—æ®µ '{field}', ç±»å‹: {type(label_data)}")
                        break
                    else:
                        print(f"    âš ï¸ å­—æ®µ '{field}' å­˜åœ¨ä½†ä¸º None")
            
            if not found_label:
                print(f"    âŒ æœªæ‰¾åˆ°ä»»ä½•æ ‡ç­¾å­—æ®µ")
                # æ‰“å°æ ·æœ¬çš„æ‰€æœ‰å±æ€§
                if hasattr(sample, '__dict__'):
                    print(f"    æ‰€æœ‰å±æ€§: {list(sample.__dict__.keys())}")
                elif hasattr(sample, '_fields'):
                    print(f"    æ‰€æœ‰å­—æ®µ: {sample._fields}")
        
        print(f"æ‰¹æ¬¡ #{i} ä¸­æœ‰æ•ˆæ ‡ç­¾æ•°é‡: {has_labels_count}/{len(batch['data_samples'])}")
        
        if has_labels_count == 0:
            print(f"âŒâŒâŒ è‡´å‘½é”™è¯¯: Batch #{i} ä¸­æ‰€æœ‰æ ·æœ¬éƒ½ç¼ºå°‘æœ‰æ•ˆæ ‡ç­¾ï¼")
            print("è¿™å°±æ˜¯å¯¼è‡´ torch.stack å¤±è´¥çš„åŸå› ã€‚")
            
            # è¯¦ç»†æ£€æŸ¥ç¬¬ä¸€ä¸ªæ ·æœ¬
            if len(batch['data_samples']) > 0:
                sample = batch['data_samples'][0]
                print(f"\nè¯¦ç»†æ£€æŸ¥ç¬¬ä¸€ä¸ªæ ·æœ¬:")
                print(f"æ ·æœ¬ç±»å‹: {type(sample)}")
                if hasattr(sample, '__dict__'):
                    for key, value in sample.__dict__.items():
                        print(f"  {key}: {type(value)} = {value}")
        else:
            print(f"âœ… æ‰¹æ¬¡ #{i} åŒ…å«æœ‰æ•ˆæ ‡ç­¾")
        
        if i >= 3:  # åªæ£€æŸ¥å‰å‡ ä¸ªæ‰¹æ¬¡
            break
    
    print("\nğŸ” === æ•°æ®åŠ è½½è°ƒè¯•ç»“æŸ ===")

if __name__ == "__main__":
    config_path = "configs/train_dinov3_mmrs1m_t20_gcu_8card.py"
    debug_dataloader(config_path)